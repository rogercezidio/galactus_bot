import json, re
from config import CARD_LIST_PATH
from bs4 import BeautifulSoup
import requests
from typing import List, Dict
from pathlib import Path
import logging
import random, datetime
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException
from utils.files import save_cards_sent

logger = logging.getLogger(__name__)

def _chrome_opts() -> Options:
    """ConfiguraÃ§Ãµes padrÃ£o para rodar Chrome em headless dentro do container."""
    opts = Options()
    opts.add_argument("--headless=new") 
    opts.add_argument("--no-sandbox")
    opts.add_argument("--disable-dev-shm-usage")
    return opts

def _url_is_image(url: str, timeout=5) -> bool:
    try:
        r = requests.head(url, allow_redirects=True, timeout=timeout)
        return r.ok and r.headers.get("content-type", "").startswith("image/")
    except Exception:
        return False

def get_card_info(name: str) -> Dict:
    slug = name.lower().replace(" ", "-")
    url  = f"https://marvelsnapzone.com/cards/{slug}/"
    decks_url = f"https://marvelsnapzone.com/decks/{slug}"

    driver = webdriver.Chrome(options=_chrome_opts())    
    
    try:
        driver.get(url)

        if "404" in driver.title or "PÃ¡gina nÃ£o encontrada" in driver.page_source:
            return {"error": f"Carta '{name}' nÃ£o encontrada.", "slug": slug, "url": url}

        h1 = WebDriverWait(driver, 5).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "main.site-main h1"))
        ).text.strip()


        img_elems = driver.find_elements(By.CSS_SELECTOR, "div.cardimage div.front img")
        image_url = img_elems[0].get_attribute("src") if img_elems else None
        if image_url and not _url_is_image(image_url):
            image_url = None                               

        desc_elems = driver.find_elements(
            By.CSS_SELECTOR, "div.cardimage div.front div.info div"
        )
        description = desc_elems[0].text.strip() if desc_elems else "DescriÃ§Ã£o nÃ£o encontrada."

        cost  = driver.find_elements(By.CSS_SELECTOR, "div.block .cost")
        power = driver.find_elements(By.CSS_SELECTOR, "div.block .power span")
        cost  = cost[0].text.strip()  if cost  else "??"
        power = power[0].text.strip() if power else "??"

        tag_elems = driver.find_elements(By.CSS_SELECTOR, "div.tags a")
        tags: List[str] = [t.text.strip() for t in tag_elems if t.text.strip()]
        series = driver.find_elements(By.XPATH, "//div[div[text()='Source']]/div[@class='info']")
        if series:
            tags.append(series[0].text.strip())

        return {
            "name": h1,
            "slug": slug,
            "url": url,
            "decks_url": decks_url,
            "image": image_url,
            "description": description,
            "cost": cost,
            "power": power,
            "tags": tags,
        }

    except TimeoutException:
        return {"error": f"Carta '{name}' nÃ£o carregou a tempo.", "slug": slug, "url": url}
    except Exception as exc:
        return {"error": f"Erro inesperado: {exc}", "slug": slug, "url": url}
    finally:
        driver.quit()
        

def format_card_message(card_data):
    base = f"**{card_data['name']}**\n\n"
    stats = f"ðŸ’° Custo: {card_data.get('cost', '??')} | ðŸ’¥ Poder: {card_data.get('power', '??')}\n\n"
    desc = f"ðŸ“ {card_data['description']}\n\n"
    tags = f"ðŸ·ï¸ {' | '.join(card_data['tags'])}\n\n" if card_data['tags'] else ""
    links = f"[ðŸ” Ver detalhes]({card_data['url']}) | [ðŸ§© Ver decks]({card_data['decks_url']})"
    return base + stats + tags + desc + links


def get_all_cards_with_tags() -> List[Dict[str, str]]:
    url = "https://marvelsnapzone.com/cards/"
    driver = webdriver.Chrome(options=_chrome_opts())
    try:
        driver.get(url)

        WebDriverWait(driver, 15).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "a.simple-card div.cardname"))
        )

        soup = BeautifulSoup(driver.page_source, "html.parser")
    finally:
        driver.quit()

    cards = []
    for anchor in soup.select("a.simple-card"):
        name_div = anchor.select_one("div.cardname")
        if not name_div:
            continue
        name = name_div.get_text(strip=True)

        tag_span = anchor.select_one("div.tags span.tag-item")
        tag_texts = [t.get_text(strip=True) for t in anchor.select("div.tags span.tag-item")]
        tag_texts = [" ".join(re.split(r"\s+", t)) for t in tag_texts if t.strip()]
        tag = " | ".join(tag_texts) if tag_texts else "Unknown"

        cards.append({"name": name, "tag": tag})

    return cards


def save_cards_to_file(cards: List[Dict[str, str]], path: str):
    with open(path, "w", encoding="utf-8") as fp:
        json.dump(cards, fp, ensure_ascii=False, indent=2)


def update_card_list():
    print("ðŸ”„ Baixando grid de cartas (grid mode)â€¦")
    cards = get_all_cards_with_tags()
    if not cards:
        print("âŒ Nada encontrado â€“ abortando.")
        return
    save_cards_to_file(cards, CARD_LIST_PATH)
    print(f"âœ… {len(cards)} cartas (com tag) salvas em {CARD_LIST_PATH}")

def _today_key() -> str:
    return datetime.date.today().isoformat()

def pick_card_without_repetition(bot_data: dict, card_names: list[str]) -> str:
    """
    Escolhe uma carta aleatÃ³ria. Garante que cada carta seja usada no mÃ¡ximo 1Ã— por dia.
    Reinicia o ciclo se esgotar todas.
    """
    data = bot_data.setdefault("cards_sent", {})
    used_today: set[str] = data.setdefault(_today_key(), set())
    remaining = [c for c in card_names if c not in used_today]
    if not remaining:                       
        used_today.clear()
        remaining = card_names
    card = random.choice(remaining)
    used_today.add(card)
    save_cards_sent(data)
    return card

_EXCLUDED = {"none", "unreleased"}


def _generate_card_list_if_missing() -> None:
    if CARD_LIST_PATH.exists():
        return
    logger.warning("%s nÃ£o encontrado â€“ gerando via scraperâ€¦", CARD_LIST_PATH)
    try:
        from utils.cards import update_card_list
        update_card_list()
    except Exception as exc:
        logger.error("Falha ao gerar card_list.json automaticamente: %s", exc)
        raise FileNotFoundError(
            f"{CARD_LIST_PATH} nÃ£o encontrado e o scraper falhou."
        ) from exc

def load_playable_card_names() -> List[str]:
    _generate_card_list_if_missing()
    with CARD_LIST_PATH.open(encoding="utf-8") as fp:
        data = json.load(fp)

    return [
        c["name"]
        for c in data
        if c.get("tag") and c["tag"].strip().lower() not in _EXCLUDED
    ]

CARDS_NAMES = load_playable_card_names()
